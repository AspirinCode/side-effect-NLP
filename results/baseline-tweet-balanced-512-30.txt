/home/users/srensi/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2018-06-02 16:13:52.521859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX TITAN Black major: 3 minor: 5 memoryClockRate(GHz): 0.98
pciBusID: 0000:83:00.0
totalMemory: 5.94GiB freeMemory: 5.86GiB
2018-06-02 16:13:52.522300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-06-02 16:13:52.830413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-02 16:13:52.830484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-06-02 16:13:52.830496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-06-02 16:13:52.830738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5664 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN Black, pci bus id: 0000:83:00.0, compute capability: 3.5)
WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.
Indexing word vectors.
Baseline Twitter Balanced - 512 batch - 30 epochs

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 100, 200)          1018400   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 100, 600)          1202400   
_________________________________________________________________
batch_normalization_1 (Batch (None, 100, 600)          2400      
_________________________________________________________________
bidirectional_2 (Bidirection (None, 100, 400)          1281600   
_________________________________________________________________
batch_normalization_2 (Batch (None, 100, 400)          1600      
_________________________________________________________________
gru_1 (GRU)                  (None, 100)               150300    
_________________________________________________________________
batch_normalization_3 (Batch (None, 100)               400       
_________________________________________________________________
dense_1 (Dense)              (None, 10)                1010      
_________________________________________________________________
batch_normalization_4 (Batch (None, 10)                40        
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 11        
=================================================================
Total params: 3,658,161
Trainable params: 2,637,541
Non-trainable params: 1,020,620
_________________________________________________________________
None
Epoch 1/30

 512/1109 [============>.................] - ETA: 8s - loss: 74.3673 - acc: 0.5117
1024/1109 [==========================>...] - ETA: 0s - loss: 73.2195 - acc: 0.5635
1109/1109 [==============================] - 9s 8ms/step - loss: 72.9430 - acc: 0.5681
Epoch 2/30

 512/1109 [============>.................] - ETA: 1s - loss: 67.0325 - acc: 0.6660
1024/1109 [==========================>...] - ETA: 0s - loss: 65.7348 - acc: 0.6953
1109/1109 [==============================] - 4s 3ms/step - loss: 65.4408 - acc: 0.7015
Epoch 3/30

 512/1109 [============>.................] - ETA: 1s - loss: 59.4082 - acc: 0.7344
1024/1109 [==========================>...] - ETA: 0s - loss: 58.1727 - acc: 0.7305
1109/1109 [==============================] - 4s 3ms/step - loss: 57.8883 - acc: 0.7340
Epoch 4/30

 512/1109 [============>.................] - ETA: 1s - loss: 52.1711 - acc: 0.7402
1024/1109 [==========================>...] - ETA: 0s - loss: 51.0130 - acc: 0.7529
1109/1109 [==============================] - 4s 3ms/step - loss: 50.7551 - acc: 0.7511
Epoch 5/30

 512/1109 [============>.................] - ETA: 1s - loss: 45.4814 - acc: 0.7598
1024/1109 [==========================>...] - ETA: 0s - loss: 44.4380 - acc: 0.7529
1109/1109 [==============================] - 4s 3ms/step - loss: 44.2068 - acc: 0.7484
Epoch 6/30

 512/1109 [============>.................] - ETA: 1s - loss: 39.3663 - acc: 0.7969
1024/1109 [==========================>...] - ETA: 0s - loss: 38.4761 - acc: 0.7715
1109/1109 [==============================] - 4s 3ms/step - loss: 38.2661 - acc: 0.7719
Epoch 7/30

 512/1109 [============>.................] - ETA: 1s - loss: 34.0320 - acc: 0.7812
1024/1109 [==========================>...] - ETA: 0s - loss: 33.1861 - acc: 0.7871
1109/1109 [==============================] - 4s 3ms/step - loss: 33.0011 - acc: 0.7890
Epoch 8/30

 512/1109 [============>.................] - ETA: 1s - loss: 29.2519 - acc: 0.7754
1024/1109 [==========================>...] - ETA: 0s - loss: 28.5073 - acc: 0.7861
1109/1109 [==============================] - 4s 3ms/step - loss: 28.3460 - acc: 0.7854
Epoch 9/30

 512/1109 [============>.................] - ETA: 1s - loss: 25.0476 - acc: 0.7988
1024/1109 [==========================>...] - ETA: 0s - loss: 24.4017 - acc: 0.7900
1109/1109 [==============================] - 4s 3ms/step - loss: 24.2525 - acc: 0.7980
Epoch 10/30

 512/1109 [============>.................] - ETA: 1s - loss: 21.3263 - acc: 0.8242
1024/1109 [==========================>...] - ETA: 0s - loss: 20.7977 - acc: 0.7969
1109/1109 [==============================] - 4s 3ms/step - loss: 20.6770 - acc: 0.7971
Epoch 11/30

 512/1109 [============>.................] - ETA: 1s - loss: 18.1509 - acc: 0.8203
1024/1109 [==========================>...] - ETA: 0s - loss: 17.6829 - acc: 0.8105
1109/1109 [==============================] - 4s 3ms/step - loss: 17.5814 - acc: 0.8097
Epoch 12/30

 512/1109 [============>.................] - ETA: 1s - loss: 15.4361 - acc: 0.8184
1024/1109 [==========================>...] - ETA: 0s - loss: 15.0517 - acc: 0.8076
1109/1109 [==============================] - 4s 3ms/step - loss: 14.9585 - acc: 0.8070
Epoch 13/30

 512/1109 [============>.................] - ETA: 1s - loss: 13.1341 - acc: 0.7871
1024/1109 [==========================>...] - ETA: 0s - loss: 12.7877 - acc: 0.7949
1109/1109 [==============================] - 4s 3ms/step - loss: 12.7088 - acc: 0.7953
Epoch 14/30

 512/1109 [============>.................] - ETA: 1s - loss: 11.0945 - acc: 0.8379
1024/1109 [==========================>...] - ETA: 0s - loss: 10.8077 - acc: 0.8271
1109/1109 [==============================] - 4s 3ms/step - loss: 10.7388 - acc: 0.8287
Epoch 15/30

 512/1109 [============>.................] - ETA: 1s - loss: 9.4217 - acc: 0.8184
1024/1109 [==========================>...] - ETA: 0s - loss: 9.1640 - acc: 0.8262
1109/1109 [==============================] - 4s 3ms/step - loss: 9.1107 - acc: 0.8269
Epoch 16/30

 512/1109 [============>.................] - ETA: 1s - loss: 8.0224 - acc: 0.8379
1024/1109 [==========================>...] - ETA: 0s - loss: 7.7960 - acc: 0.8330
1109/1109 [==============================] - 4s 3ms/step - loss: 7.7433 - acc: 0.8341
Epoch 17/30

 512/1109 [============>.................] - ETA: 1s - loss: 6.8082 - acc: 0.8223
1024/1109 [==========================>...] - ETA: 0s - loss: 6.6227 - acc: 0.8203
1109/1109 [==============================] - 4s 3ms/step - loss: 6.5811 - acc: 0.8233
Epoch 18/30

 512/1109 [============>.................] - ETA: 1s - loss: 5.7429 - acc: 0.8770
1024/1109 [==========================>...] - ETA: 0s - loss: 5.6237 - acc: 0.8525
1109/1109 [==============================] - 4s 3ms/step - loss: 5.5914 - acc: 0.8485
Epoch 19/30

 512/1109 [============>.................] - ETA: 1s - loss: 4.9239 - acc: 0.8555
1024/1109 [==========================>...] - ETA: 0s - loss: 4.8057 - acc: 0.8584
1109/1109 [==============================] - 4s 3ms/step - loss: 4.7778 - acc: 0.8575
Epoch 20/30

 512/1109 [============>.................] - ETA: 1s - loss: 4.2827 - acc: 0.8242
1024/1109 [==========================>...] - ETA: 0s - loss: 4.1587 - acc: 0.8369
1109/1109 [==============================] - 4s 3ms/step - loss: 4.1370 - acc: 0.8350
Epoch 21/30

 512/1109 [============>.................] - ETA: 1s - loss: 3.7086 - acc: 0.8066
1024/1109 [==========================>...] - ETA: 0s - loss: 3.5915 - acc: 0.8281
1109/1109 [==============================] - 4s 3ms/step - loss: 3.5678 - acc: 0.8305
Epoch 22/30

 512/1109 [============>.................] - ETA: 1s - loss: 3.1826 - acc: 0.8477
1024/1109 [==========================>...] - ETA: 0s - loss: 3.0884 - acc: 0.8584
1109/1109 [==============================] - 4s 3ms/step - loss: 3.0759 - acc: 0.8575
Epoch 23/30

 512/1109 [============>.................] - ETA: 1s - loss: 2.7218 - acc: 0.8730
1024/1109 [==========================>...] - ETA: 0s - loss: 2.6975 - acc: 0.8525
1109/1109 [==============================] - 4s 3ms/step - loss: 2.6933 - acc: 0.8512
Epoch 24/30

 512/1109 [============>.................] - ETA: 1s - loss: 2.4294 - acc: 0.8633
1024/1109 [==========================>...] - ETA: 0s - loss: 2.3823 - acc: 0.8584
1109/1109 [==============================] - 4s 3ms/step - loss: 2.3746 - acc: 0.8548
Epoch 25/30

 512/1109 [============>.................] - ETA: 1s - loss: 2.1645 - acc: 0.8457
1024/1109 [==========================>...] - ETA: 0s - loss: 2.1096 - acc: 0.8545
1109/1109 [==============================] - 4s 3ms/step - loss: 2.0994 - acc: 0.8557
Epoch 26/30

 512/1109 [============>.................] - ETA: 1s - loss: 1.9111 - acc: 0.8711
1024/1109 [==========================>...] - ETA: 0s - loss: 1.8818 - acc: 0.8711
1109/1109 [==============================] - 4s 3ms/step - loss: 1.8725 - acc: 0.8720
Epoch 27/30

 512/1109 [============>.................] - ETA: 1s - loss: 1.7381 - acc: 0.8730
1024/1109 [==========================>...] - ETA: 0s - loss: 1.7077 - acc: 0.8701
1109/1109 [==============================] - 4s 3ms/step - loss: 1.7045 - acc: 0.8702
Epoch 28/30

 512/1109 [============>.................] - ETA: 1s - loss: 1.5869 - acc: 0.8555
1024/1109 [==========================>...] - ETA: 0s - loss: 1.5945 - acc: 0.8359
1109/1109 [==============================] - 4s 3ms/step - loss: 1.5875 - acc: 0.8377
Epoch 29/30

 512/1109 [============>.................] - ETA: 1s - loss: 1.4529 - acc: 0.8711
1024/1109 [==========================>...] - ETA: 0s - loss: 1.4459 - acc: 0.8623
1109/1109 [==============================] - 4s 3ms/step - loss: 1.4416 - acc: 0.8638
Epoch 30/30

 512/1109 [============>.................] - ETA: 1s - loss: 1.2952 - acc: 0.8926
1024/1109 [==========================>...] - ETA: 0s - loss: 1.2959 - acc: 0.8838
1109/1109 [==============================] - 4s 3ms/step - loss: 1.3040 - acc: 0.8774
Accuracy: 77.62%
[[100  37]
 [ 25 115]]
0.7876712328767124
0.7633587786259542
